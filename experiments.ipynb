{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y00RfkU5gl3e"
      },
      "source": [
        "# pip install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZwmLEU0UAqy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ABdD1BElsnw"
      },
      "outputs": [],
      "source": [
        "tensorboard_log = '/xx/' # replace with your directory\n",
        "\n",
        "os.makedirs(tensorboard_log, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7I_gQZx_ND-"
      },
      "outputs": [],
      "source": [
        "\n",
        "df_all_targets = pd.DataFrame()\n",
        "\n",
        "model_name = 'PPO'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBfYaCjEgokt"
      },
      "outputs": [],
      "source": [
        "pip install gymnasium\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttq6_9qDgp-c"
      },
      "outputs": [],
      "source": [
        "pip install \"stable-baselines3[extra]>=2.0.0a4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6x7QilC85No"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "\n",
        "from stable_baselines3 import PPO, A2C, DQN\n",
        "from stable_baselines3.common.env_util import make_vec_env, SubprocVecEnv, DummyVecEnv\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.callbacks import CheckpointCallback, EvalCallback\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlZPhtptcf9v"
      },
      "source": [
        "## set reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfbdcxuNcker"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "os.environ['PYTHONASHSEED'] = '0'\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "\n",
        "seed = 0\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEsAU3iFchK7"
      },
      "source": [
        "# utils functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zM7C0pJLRwhY"
      },
      "outputs": [],
      "source": [
        "    def load_topic_target_location(topic_id,target_recall):\n",
        "      ## load data\n",
        "\n",
        "      vector_size = 100 # vector size to feed NN\n",
        "\n",
        "      all_vectors = [[-1]*vector_size for i in range(vector_size)]\n",
        "\n",
        "      target_location = -1 # initial\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      n_docs = len(doc_rank_dic[topic_id])  # total n. docs in topic\n",
        "      rel_list = rank_rel_dic[topic_id]  # list binary rel of ranked docs\n",
        "\n",
        "      # get batches\n",
        "      windows = make_windows(vector_size, n_docs)\n",
        "\n",
        "      window_size = windows[0][1]\n",
        "\n",
        "      # calculate batches\n",
        "      rel_cnt,rel_rate, n_docs_wins = get_rel_cnt_rate(windows, window_size, rel_list)\n",
        "\n",
        "\n",
        "\n",
        "      n_rel = sum(rel_cnt)\n",
        "      prev = sum(rel_cnt)/n_docs\n",
        "\n",
        "\n",
        "      #update all vector with all possible examined states\n",
        "      for i in range(vector_size):\n",
        "        all_vectors[i][0:i+1] = rel_rate[0:i+1] # update examined part\n",
        "\n",
        "        #calculate target recall stopping pos\n",
        "        #mark only 1st recall achieved stopping position\n",
        "        if (sum(rel_cnt[0:i+1]) / sum(rel_cnt)) >= target_recall and target_location == -1:\n",
        "          target_location = i\n",
        "\n",
        "\n",
        "      return topic_id, n_docs, n_rel, prev, target_location"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BEFPXMBfgpR"
      },
      "outputs": [],
      "source": [
        "def get_rel_cnt_rate(windows, window_size, rel_list):\n",
        "\n",
        "    # x-values are the cnt at which relevant documents occur in the window\n",
        "    x = [np.sum(rel_list[w_s:w_e]) for (w_s,w_e) in windows]\n",
        "\n",
        "    # y-values are the rate at which relevant documents occur in the window\n",
        "    y = [np.sum(rel_list[w_s:w_e]) for (w_s,w_e) in windows]\n",
        "    y = [y_i/window_size for y_i in y]\n",
        "\n",
        "\n",
        "    # z-values are the cnt of documents in the window\n",
        "    z = [len(rel_list[w_s:w_e]) for (w_s,w_e) in windows]\n",
        "\n",
        "\n",
        "    # convert lists to numpy arrays\n",
        "    x = np.array(x)\n",
        "    y = np.array(y)\n",
        "    z= np.array(z)\n",
        "    return (x,y,z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "re1zRU2ZfCmb"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# IMPORT LIBRARIES\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "from scipy.optimize import curve_fit\n",
        "import random\n",
        "import glob\n",
        "import subprocess\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.integrate import simps\n",
        "from scipy.stats import norm\n",
        "import os\n",
        "\n",
        "import scipy\n",
        "\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZ_VXtt5dYfZ"
      },
      "outputs": [],
      "source": [
        "DIR = '/xxhome/' # replace with utils home directory\n",
        "\n",
        "\n",
        "sys.path.append(DIR)\n",
        "\n",
        "# import utils fns\n",
        "from utils.read_data_fns import *\n",
        "from utils.eval_fns import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6kwyfWZvYVs"
      },
      "outputs": [],
      "source": [
        "# LOAD TOPIC RELEVANCE DATA\n",
        "def load_rel_data(qrels):\n",
        "  qrel_fname =  os.path.join(DIR, qrels)\n",
        "  with open(qrel_fname, 'r') as infile:\n",
        "      qrels_data = infile.readlines()\n",
        "  query_rel_dic = make_rel_dic(qrels_data) # make dictionary of list of docids relevant to each queryid\n",
        "\n",
        "  return qrel_fname, query_rel_dic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-_sA4fUvpJh"
      },
      "outputs": [],
      "source": [
        "# LOAD RUN DATA\n",
        "def load_run_data(run):\n",
        "  run_fname = os.path.join(DIR, run)\n",
        "  with open(run_fname, 'r') as infile:\n",
        "    run_data = infile.readlines()\n",
        "  doc_rank_dic = make_rank_dic(run_data)  # make dictionary of ranked docids for each queryid\n",
        "  rank_rel_dic = make_rank_rel_dic(query_rel_dic,doc_rank_dic) # make dic of list relevances of ranked docs for each queryid\n",
        "\n",
        "  return doc_rank_dic, rank_rel_dic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcChrHeiJjDv"
      },
      "source": [
        "# clf functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z69DZFLa3S3p"
      },
      "outputs": [],
      "source": [
        "# import\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#modeling\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#evaluation\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "\n",
        "# import NLP libraries\n",
        "### import libraries\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "\n",
        "import pickle\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse import vstack\n",
        "\n",
        "\n",
        "def run_classification_model_tfidf(query_id, n_samp_docs, n_docs, labels, features, clf_name, imbalance_handle):\n",
        "\n",
        "    features = vstack(features) # combine sparse rows into single sparse matrix\n",
        "\n",
        "\n",
        "    #split train & test sets\n",
        "    train_x = features[0:n_samp_docs]\n",
        "    train_y = labels[0:n_samp_docs]\n",
        "    valid_x = features[n_samp_docs:n_docs]\n",
        "    valid_y = labels[n_samp_docs:n_docs]\n",
        "\n",
        "\n",
        "    # calculate relv, non-relv\n",
        "    relv_cnt = sum(train_y)\n",
        "    non_relv_cnt = len(train_y) - relv_cnt\n",
        "\n",
        "\n",
        "    if imbalance_handle == 'cost_sensitive_manual':\n",
        "      # manually assign majority and minority to either 0 or 1 based on sample\n",
        "      if relv_cnt >= non_relv_cnt:\n",
        "        majority_class = 1\n",
        "        minority_class = 0\n",
        "        IR = non_relv_cnt/relv_cnt\n",
        "        class_weight={majority_class:IR, minority_class:1}\n",
        "      else:\n",
        "        majority_class = 0\n",
        "        minority_class = 1\n",
        "        IR = relv_cnt/non_relv_cnt\n",
        "        class_weight={majority_class:IR, minority_class:1}\n",
        "\n",
        "      clf = LogisticRegression(solver=solver, random_state=0, C=1.0, max_iter=10000, class_weight = class_weight)\n",
        "\n",
        "\n",
        "    accuracy, f1, predictions = train_model_save_threshold(query_id,clf_name, clf, train_x, train_y, valid_x, valid_y)\n",
        "\n",
        "    predictions = predictions.astype(int)\n",
        "\n",
        "    return accuracy, f1, predictions\n",
        "\n",
        "\n",
        "\n",
        "def train_model_save_threshold(topic_id, clf_name, classifier, feature_vector_train, label, feature_vector_valid, valid_y, is_neural_net=False):\n",
        "      # fit the training dataset on the classifier\n",
        "      classifier.fit(feature_vector_train, label)\n",
        "\n",
        "      #set threshold optimised F1 (models default)\n",
        "      model_threshold = 0.5\n",
        "\n",
        "      # get clf labels\n",
        "      predictions = (classifier.predict_proba(feature_vector_valid)[:,1] >= model_threshold).astype(bool) # set threshold to threshold_list[i]\n",
        "\n",
        "\n",
        "      acc = metrics.accuracy_score(valid_y, predictions) * 100\n",
        "      f1 = metrics.f1_score(valid_y, predictions, average='macro') * 100\n",
        "\n",
        "      return round(acc,3), round(f1,3), predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgZkVR22TjkR"
      },
      "source": [
        "# Callback functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u15rfDErvW4i"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "import numpy as np\n",
        "\n",
        "class EarlyStoppingCallback(BaseCallback):\n",
        "    def __init__(self, patience: int, min_delta: float = 0.001, verbose: int = 0):\n",
        "        super(EarlyStoppingCallback, self).__init__(verbose)\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best_mean_reward = -np.inf\n",
        "        self.no_improvement_steps = 0\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        # check if an episode has ended\n",
        "        if 'episode' in self.locals['infos'][-1]:\n",
        "            # get latest episode reward mean\n",
        "            mean_reward = np.mean(self.locals['infos'][-1]['episode']['r'])\n",
        "\n",
        "            # check if the mean reward has improved\n",
        "            if mean_reward > self.best_mean_reward + self.min_delta:\n",
        "                # improvement, update the best reward\n",
        "                self.best_mean_reward = mean_reward\n",
        "                self.no_improvement_steps = 0\n",
        "            else:\n",
        "                # no improvement\n",
        "                self.no_improvement_steps += 1\n",
        "\n",
        "            # if no improvement for `self.patience` steps, stop training\n",
        "            if self.no_improvement_steps > self.patience:\n",
        "                if self.verbose > 0:\n",
        "                    print(\"Early stopping triggered: Training stopped at step {}\".format(self.num_timesteps))\n",
        "                return False  # stop the training\n",
        "\n",
        "        return True  # continue training\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVK3hivQH3eh"
      },
      "source": [
        "# TAREnv class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ekoUgp7H3ei"
      },
      "outputs": [],
      "source": [
        "# reward functions to handle different powers m, and n\n",
        "def cumulative_reward(x, T, B, m, n):\n",
        "    if x <= T:\n",
        "        return (x / T) ** m\n",
        "    else:\n",
        "        return ((B - x) / (B - T)) ** n\n",
        "\n",
        "def stepwise_reward(x, T, B, m, n):\n",
        "    if x <= T:\n",
        "        return (1 / T ** m) * (x ** m - (x - 1) ** m)\n",
        "    else:\n",
        "        return (1 / (B - T) ** n) * ((B - x) ** n - (B - (x - 1)) ** n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4m31be1WH3ej"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "\n",
        "\n",
        "ALL_VECTORS_PREDICTIONS_DIC = {}\n",
        "SELECTED_TOPICS_WITHOUT_TARGET = []\n",
        "ALL_VECTORS_PREDICTIONS_DIC_EXIST = False\n",
        "\n",
        "SELECTED_TOPICS = [] # keep track of all randomly selected topics\n",
        "SELECTED_TOPICS_TARGET = []\n",
        "class TAREnv(gym.Env):\n",
        "\n",
        "\n",
        "\n",
        "    def __init__(self, target_recall = None, topics_list = None, topic_id= None, size=100 , render_mode=None):\n",
        "\n",
        "\n",
        "\n",
        "        self.size = size  # The size of the ranking relv vector\n",
        "\n",
        "        #observation is 1D np array size array of relv vector\n",
        "        self.observation_space = spaces.Box(-1,  1, shape=(size+2,), dtype=np.float32) #with clf\n",
        "\n",
        "        # 2 actions, corresponding to \"next\", \"stop\"\n",
        "        self.action_space = spaces.Discrete(2)\n",
        "\n",
        "        # Set up some properties\n",
        "        self.done = False\n",
        "        self.reward = 0\n",
        "        self.hit, self.miss = 0, 0\n",
        "\n",
        "\n",
        "\n",
        "        # Set up the TAR\n",
        "        self.vector_size = size\n",
        "\n",
        "\n",
        "\n",
        "        # current position and stop position\n",
        "        self._agent_location = 0 # -1: target,\n",
        "        self._target_location = -1 #dummy value\n",
        "\n",
        "        # keep predicted recall so far\n",
        "        self.recall = 0\n",
        "        self.target_recall = target_recall\n",
        "\n",
        "        # topic data\n",
        "\n",
        "        self.topics_list = topics_list\n",
        "        self.topic_id = topic_id # for single env\n",
        "\n",
        "        self.windows = 0\n",
        "        self.window_size = 0\n",
        "\n",
        "        #for vec env\n",
        "        if topic_id is None:\n",
        "          # checking whether the generated random number is not repeated\n",
        "          while ( len(SELECTED_TOPICS) <= len(topics_list)):\n",
        "            t = random.choice(topics_list)\n",
        "            if t not in SELECTED_TOPICS:\n",
        "              # include target recall with topic\n",
        "              if TRAINING:\n",
        "                # appending the random number to the resultant list, if the condition is true\n",
        "                SELECTED_TOPICS.append(t)\n",
        "                self.topic_id = t.split('_',1)[0]\n",
        "                self.target_recall = float(t.split('_',1)[1])\n",
        "              #if testing no need for target recall with topic\n",
        "              else:\n",
        "                # appending the random number to the resultant list, if the condition is true\n",
        "                SELECTED_TOPICS.append(t)\n",
        "                self.topic_id = t\n",
        "                self.target_recall = target_recall\n",
        "              break\n",
        "\n",
        "\n",
        "          #ACTIVATE on TRAINING\n",
        "          # use same ordered list of topics across diffreent runs\n",
        "          if TRAINING:\n",
        "            global SELECTED_TOPICS_ORDERERD_INDEX\n",
        "            t = SELECTED_TOPICS_ORDERERD[SELECTED_TOPICS_ORDERERD_INDEX]\n",
        "            self.topic_id = t.split('_',1)[0]\n",
        "            self.target_recall = float(t.split('_',1)[1])\n",
        "            SELECTED_TOPICS_ORDERERD_INDEX += 1\n",
        "        else:\n",
        "           self.topic_id = topic_id # for single env\n",
        "\n",
        "\n",
        "\n",
        "        self.n_docs = 0\n",
        "        self.rel_cnt = []\n",
        "        self.rel_rate = []\n",
        "        self.n_samp_docs = 0\n",
        "        self.n_samp_docs_after_target =  0\n",
        "        self.n_docs_wins = []\n",
        "        self.rel_list = 0\n",
        "        self.text_list = ''\n",
        "        self.tfidf_list = []\n",
        "        self.all_vectors = []\n",
        "        self.all_vectors_target = []\n",
        "        self.all_vectors_prediction = []\n",
        "\n",
        "        # Define constants for clearer code\n",
        "        self.NEXT = 0\n",
        "        self.STOP = 1\n",
        "\n",
        "\n",
        "        self.load_data_flag = True\n",
        "        self.load_data(self.topic_id)\n",
        "\n",
        "        self.first_step_flag = True\n",
        "\n",
        "        #initialize environment each time for each topic\n",
        "        self.reset()\n",
        "\n",
        "\n",
        "    def load_data(self, topic_id):\n",
        "\n",
        "      # load data only once when self._agent_location ==0\n",
        "      if self._agent_location == 0 :\n",
        "\n",
        "        all_vectors = [[-1]*self.vector_size for i in range(self.vector_size)]\n",
        "        all_vectors_target = [[-1]*(self.vector_size+2) for i in range((self.vector_size))] # +2 for current index &target, DONT ADD IT FOR ROWS ONLY COLS\n",
        "        all_vectors_prediction = [[-1]*(self.vector_size+2) for i in range((self.vector_size))] # +2 for current index &target, DONT ADD IT FOR ROWS ONLY COLS\n",
        "\n",
        "        topic_id = self.topic_id\n",
        "\n",
        "\n",
        "        n_docs = len(doc_rank_dic[topic_id])  # total n. docs in topic\n",
        "        rel_list = rank_rel_dic[topic_id]  # list binary rel of ranked docs\n",
        "        text_list = rank_text_dic[topic_id]  # list text feature of ranked docs\n",
        "        tfidf_list = rank_tfidf_dic[topic_id]  # list text feature of ranked docs\n",
        "\n",
        "\n",
        "        # get batches\n",
        "        windows = make_windows(self.vector_size, n_docs)\n",
        "\n",
        "        window_size = windows[0][1]\n",
        "\n",
        "        # calculate batches\n",
        "        rel_cnt,rel_rate, n_docs_wins = get_rel_cnt_rate(windows, window_size, rel_list)\n",
        "\n",
        "\n",
        "        self.n_docs = n_docs\n",
        "        self.rel_cnt = rel_cnt\n",
        "        self.rel_rate = rel_rate\n",
        "        self.n_docs_wins = n_docs_wins\n",
        "        self.rel_list = rel_list\n",
        "        self.text_list = text_list\n",
        "        self.tfidf_list = tfidf_list\n",
        "        self.windows = windows\n",
        "        self.window_size = window_size\n",
        "\n",
        "        #update all vector with all possible examined states\n",
        "        for i in range(self.vector_size):\n",
        "          all_vectors[i][0:i+1] = rel_rate[0:i+1] # update examined part\n",
        "\n",
        "          all_vectors_target[i][-1] = self.target_recall # include target recall as last element\n",
        "          all_vectors_target[i][-2] = i # mark current examined index\n",
        "\n",
        "          #if clf not used\n",
        "          all_vectors_target[i][0:i+1] = rel_rate[0:i+1] # update examined part only\n",
        "\n",
        "          #if clf used\n",
        "          if self.topic_id not in SELECTED_TOPICS_WITHOUT_TARGET:\n",
        "            #run clf only once\n",
        "            all_vectors_target[i][0:-2] = self.get_clf_predictions(i) # update examined with tl & non-examined part with clf predictions\n",
        "          else:\n",
        "            saved_all_vectors_target = ALL_VECTORS_PREDICTIONS_DIC[self.topic_id]\n",
        "            all_vectors_target[i][0:-2] = saved_all_vectors_target[i][0:-2]\n",
        "\n",
        "          #calculate target recall stopping pos\n",
        "          #mark only 1st recall achieved stopping position\n",
        "          if (sum(self.rel_cnt[0:i+1]) / sum(self.rel_cnt)) >= self.target_recall and self._target_location == -1 and i < self.vector_size: #7-10-24: i< self.vector_size\n",
        "            self._target_location = i\n",
        "\n",
        "\n",
        "        #update after passing through all batches\n",
        "        SELECTED_TOPICS_WITHOUT_TARGET.append(self.topic_id)\n",
        "        ALL_VECTORS_PREDICTIONS_DIC[self.topic_id] = all_vectors_target\n",
        "\n",
        "        self.all_vectors = all_vectors\n",
        "        self.all_vectors_target = all_vectors_target\n",
        "\n",
        "    def get_clf_predictions(self,i):\n",
        "\n",
        "      # Initialise count of documents in sample\n",
        "      tmp_n_samp_docs = int(np.sum(self.n_docs_wins[0:i+1]))\n",
        "\n",
        "      clf_name = 'LR-TFIDF'\n",
        "      dataset_imbalance_handle = 'cost_sensitive_manual'\n",
        "      acc, f1, predictions = run_classification_model_tfidf(self.topic_id, tmp_n_samp_docs, self.n_docs, self.rel_list, self.tfidf_list, clf_name, dataset_imbalance_handle)\n",
        "\n",
        "      rel_pred_list = list(self.rel_list[0:tmp_n_samp_docs+1])+list(predictions)\n",
        "      rel_cnt_wins, rel_pred_wins, n_docs_wins  = get_rel_cnt_rate(self.windows, self.window_size, rel_pred_list)\n",
        "\n",
        "      return rel_pred_wins # update examined&non-examined part with tl & clf predictions\n",
        "\n",
        "#######################################################################################\n",
        "\n",
        "\n",
        "    def _get_obs(self):\n",
        "        return  np.array(self.all_vectors_target[self._agent_location], dtype=np.float32)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def _get_info(self):\n",
        "\n",
        "\n",
        "\n",
        "        return {\n",
        "                \"topic_id\": self.topic_id,\n",
        "                \"recall\": round((self.recall),3),\n",
        "                \"cost\": round(((self._agent_location +1 )/100),3), # each vec pos == 1% of collection +1 bc 1st loc [0] is 1% cost\n",
        "                \"e_cost\": (round((((self._agent_location)-(self._target_location))/100),3)), # CostDiff\n",
        "                \"distance\": (self._agent_location - self._target_location),\n",
        "                \"agent\": (self._agent_location),\n",
        "                \"target\": (self._target_location),\n",
        "                \"agent_vector\": np.array(self.all_vectors_target[self._agent_location]),\n",
        "                \"terminal_observation\": np.array(self.all_vectors_target[self._target_location])} # target_vector named terminal_observation needed for SB3 vec_env\n",
        "#######################################################################################\n",
        "\n",
        "\n",
        "    def reset(self,seed=0):\n",
        "\n",
        "        # re-load data 1st time for vec_env\n",
        "        if self.load_data_flag:\n",
        "          self.load_data(self.topic_id)\n",
        "          self.load_data_flag = False\n",
        "\n",
        "        self._agent_location = 0\n",
        "        self.n_samp_docs =  sum(self.n_docs_wins[0:self._agent_location+1])\n",
        "        self.n_samp_docs_after_target =  sum(self.n_docs_wins[self._target_location:self._agent_location+1])\n",
        "        self.recall = sum(self.rel_cnt[0:self._agent_location+1]) / sum(self.rel_cnt)\n",
        "\n",
        "        state = self.all_vectors[self._agent_location]\n",
        "\n",
        "        observation = self._get_obs()\n",
        "        info = self._get_info()\n",
        "\n",
        "        self.reward = 0\n",
        "\n",
        "        #return state\n",
        "        return observation, info\n",
        "\n",
        "#######################################################################################\n",
        "\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "        truncated = False\n",
        "        terminated = False\n",
        "\n",
        "        if self._agent_location >= self.vector_size-1:\n",
        "          self.done = True\n",
        "          truncated = True\n",
        "          self.reward = 0\n",
        "\n",
        "        if self._agent_location >= self.vector_size-2 and action == self.NEXT:\n",
        "          self.done = True\n",
        "          truncated = True\n",
        "          self.reward = 0\n",
        "\n",
        "        if action == self.STOP:\n",
        "          terminated = True\n",
        "          self.reward = 0\n",
        "\n",
        "\n",
        "        if action == self.NEXT:\n",
        "            if self.first_step_flag:\n",
        "              self._agent_location = self._agent_location # dont move next, examine 1st portion at pos [0]\n",
        "              self.first_step_flag = False\n",
        "            else:\n",
        "              self._agent_location += 1 # move to next portion (examined)\n",
        "\n",
        "            self.n_samp_docs =  sum(self.n_docs_wins[0:self._agent_location+1])\n",
        "            self.n_samp_docs_after_target =  sum(self.n_docs_wins[self._target_location:self._agent_location+1])\n",
        "            self.recall = sum(self.rel_cnt[0:self._agent_location+1]) / sum(self.rel_cnt)\n",
        "\n",
        "        observation = self._get_obs()\n",
        "        info = self._get_info()\n",
        "\n",
        "        # to get more easy readable formula\n",
        "        reward_target_loc = self._target_location+1\n",
        "        reward_agent_loc = self._agent_location+1\n",
        "        reward_vector_size = self.vector_size\n",
        "\n",
        "\n",
        "        global m,n #reusable for linear vs nonlinear\n",
        "        self.reward = stepwise_reward(reward_agent_loc, reward_target_loc, reward_vector_size, m, n)\n",
        "\n",
        "\n",
        "        return observation, self.reward, terminated, truncated, info\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def close(self):\n",
        "        # we dont need close\n",
        "        return\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h89W_EyKUd8"
      },
      "source": [
        "# run experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a26vbCk89NW"
      },
      "outputs": [],
      "source": [
        "TRAINING = True\n",
        "\n",
        "#penalise undershooting, tolerance with overshooting\n",
        "m = 4\n",
        "n = 1/4\n",
        "model_name = 'non_lin'\n",
        "\n",
        "#penalise overshooting, tolerance with undershooting\n",
        "m = 1/4\n",
        "n = 4\n",
        "model_name = 'non_lin_cost_obj'\n",
        "\n",
        "\n",
        "#blalanced\n",
        "m = 1\n",
        "n = 1\n",
        "model_name = 'lin_clf_lr'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "total_runs = 5 # if choose Deterministic = False (Stochatic) in predict()\n",
        "\n",
        "\n",
        "target_recalls = [1.0, 0.99, 0.95, 0.9, 0.85, 0.8, 0.75, 0.7]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVsh0NNiKUd9"
      },
      "outputs": [],
      "source": [
        "df_all_targets = pd.DataFrame()\n",
        "\n",
        "DRL_DIR = '/xx/' # replace with working directory\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a-hmJB3KUd9"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwFBSDMUKUd-"
      },
      "outputs": [],
      "source": [
        "TRAINING = True\n",
        "topic_set = 'training'\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6lggvnCKUd-"
      },
      "outputs": [],
      "source": [
        "training_dataset = 'CLEF'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoAYq99JKUd-"
      },
      "source": [
        "#### sort topics by target location"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NUS2o6YKUd_"
      },
      "outputs": [],
      "source": [
        "dataset_name = 'CLEF'\n",
        "\n",
        "qrels = \"/data/qrels/CLEF2017_qrels.txt\"\n",
        "\n",
        "\n",
        "qrel_fname, query_rel_dic = load_rel_data(qrels)\n",
        "\n",
        "run = \"/data/rankings/clef2017_training_ranking.txt\"\n",
        "\n",
        "doc_rank_dic, rank_rel_dic, rank_text_dic, rank_tfidf_dic = load_run_data_with_text_tfidf(run, dataset_name, topic_set)\n",
        "\n",
        "topics_list = make_topics_list(doc_rank_dic,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNR6TB0YKUd_"
      },
      "outputs": [],
      "source": [
        "#remove topic CD008760 last element, contains 64 items only, < 100 vector size\n",
        "topics_list= topics_list[:-1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQGN88mEKUeA"
      },
      "outputs": [],
      "source": [
        "topics_info = []\n",
        "\n",
        "for target_recall in target_recalls:\n",
        "  for t in topics_list:\n",
        "    topic_id, n_docs, n_rel, prev, target_location = load_topic_target_location(t,target_recall)\n",
        "    topic_id_target_recall = topic_id + \"_\" + str(target_recall)\n",
        "    print(topic_id, n_docs, n_rel, round(prev,3), target_location)\n",
        "    topics_info.append([topic_id, n_docs, n_rel, prev, target_recall, target_location, topic_id_target_recall])\n",
        "\n",
        "topics_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7IXYoJdKUeA"
      },
      "outputs": [],
      "source": [
        "\n",
        "df = pd.DataFrame(topics_info, columns=['topic_id', 'n_docs', 'n_rel', 'prev', 'target_recall', 'target_location', 'topic_id_target_recall'])\n",
        "df = df.sort_values(by=['target_recall', 'target_location'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0JivkKUKUeA"
      },
      "outputs": [],
      "source": [
        "sorted_target_loc_topics = list(df['topic_id_target_recall'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####load clf rel dic if exist"
      ],
      "metadata": {
        "id": "nRHt8h4JMgo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = 'CLEF'\n",
        "topic_set = 'training'\n",
        "\n",
        "# file name\n",
        "ALL_VECTORS_PREDICTIONS_DIC_file_name = dataset_name +'_'+ topic_set +'_'+ 'ALL_VECTORS_PREDICTIONS_DIC.pkl'\n",
        "ALL_VECTORS_PREDICTIONS_DIC_file_name = DRL_DIR+'data/'+ALL_VECTORS_PREDICTIONS_DIC_file_name\n",
        "\n",
        "# check if the file exists\n",
        "if not os.path.exists(ALL_VECTORS_PREDICTIONS_DIC_file_name):\n",
        "    # if doesn't exist, create an empty dictionary\n",
        "    ALL_VECTORS_PREDICTIONS_DIC = {}\n",
        "    SELECTED_TOPICS_WITHOUT_TARGET = []\n",
        "    ALL_VECTORS_PREDICTIONS_DIC_EXIST = False\n",
        "\n",
        "else:\n",
        "    # if exists, load the dictionary from the file\n",
        "    with open(ALL_VECTORS_PREDICTIONS_DIC_file_name, \"rb\") as f:\n",
        "        ALL_VECTORS_PREDICTIONS_DIC = pickle.load(f)\n",
        "\n",
        "    SELECTED_TOPICS_WITHOUT_TARGET = list(ALL_VECTORS_PREDICTIONS_DIC.keys())\n",
        "    ALL_VECTORS_PREDICTIONS_DIC_EXIST = True\n"
      ],
      "metadata": {
        "id": "agtOQA-uMSIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUBK7wAeKUeB"
      },
      "source": [
        "####ordered topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yr2MsiaIKUeB"
      },
      "outputs": [],
      "source": [
        "TRAINING = True\n",
        "\n",
        "SELECTED_TOPICS_ORDERERD = sorted_target_loc_topics\n",
        "SELECTED_TOPICS_ORDERERD_INDEX = 0\n",
        "\n",
        "SELECTED_TOPICS_TARGET = target_recalls\n",
        "SELECTED_TOPICS_TARGET_INDEX = 0\n",
        "\n",
        "# Instantiate the vec env\n",
        "\n",
        "#random topic selection for each env instance\n",
        "SELECTED_TOPICS = [] # reset before/after each call, keep track of all randomly selected topics\n",
        "SELECTED_TOPICS_TARGET = []\n",
        "\n",
        "n_envs=len(sorted_target_loc_topics)\n",
        "vec_env = make_vec_env(TAREnv, n_envs=len(sorted_target_loc_topics), env_kwargs=dict(target_recall=None, topics_list = sorted_target_loc_topics, topic_id=None, size=100, render_mode='human'))\n",
        "\n",
        "SELECTED_TOPICS = [] # reset before/after each call, keep track of all randomly selected topics\n",
        "SELECTED_TOPICS_TARGET = []\n",
        "\n",
        "train_size = len(topics_list)*len(target_recalls)\n",
        "\n",
        "\n",
        "vec_env_train = vec_env\n",
        "\n",
        "#save dic for first time\n",
        "if not ALL_VECTORS_PREDICTIONS_DIC_EXIST:\n",
        "    # Save the dictionary to a file\n",
        "    with open(ALL_VECTORS_PREDICTIONS_DIC_file_name, 'wb') as f:\n",
        "        pickle.dump(ALL_VECTORS_PREDICTIONS_DIC, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNSy3lVoKUeB"
      },
      "source": [
        "#### Hyperparameter Settings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def nearest_factor_of(target, total):\n",
        "    # find all factors of `total`\n",
        "    factors = [i for i in range(1, total + 1) if total % i == 0]\n",
        "\n",
        "    # find the factor closest to the target\n",
        "    closest_factor = min(factors, key=lambda x: abs(x - target))\n",
        "    return closest_factor\n",
        "\n"
      ],
      "metadata": {
        "id": "wIYyQb3HH2p4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5pu01e9KUeB"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Train the agent\n",
        "\n",
        "n_envs=len(sorted_target_loc_topics)\n",
        "\n",
        "\n",
        "learning_rate_initial = 0.0003\n",
        "\n",
        "\n",
        "learning_rate = learning_rate_initial\n",
        "learning_rate_type = '_lr_static'\n",
        "\n",
        "\n",
        "ent_coef = 0.1\n",
        "\n",
        "gamma = 0.99\n",
        "gae_lambda = 0.98\n",
        "clip_range=0.1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "n_epochs =10\n",
        "\n",
        "n_steps = 10\n",
        "\n",
        "\n",
        "\n",
        "total_rollout = n_steps * n_envs  # Total rollout buffer size\n",
        "target_mini_batch = int(1/4 * total_rollout)  # Target value (1/4 of total)\n",
        "\n",
        "\n",
        "# get the nearest factor\n",
        "batch_size = nearest_factor_of(total_rollout, target_mini_batch)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "nn_nodes = 64\n",
        "\n",
        "policy_kwargs = dict(\n",
        "    net_arch=[nn_nodes, nn_nodes]  # Two hidden layers with nn_nodes\n",
        ")\n",
        "\n",
        "\n",
        "total_timesteps = 20_000_000\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3if69onoKUeC"
      },
      "source": [
        "####  PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BT6P-YGiKUeD"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "tb_log_name = model_name+\"_\"+training_dataset+\"_nstps\"+str(n_steps)+\"_btch\"+str(batch_size)+\"_ts\"+str(total_timesteps)+ \"_ent\"+str(ent_coef)+\"_epch\"+str(n_epochs)+learning_rate_type+str(learning_rate_initial)+\"_clip\"+str(clip_range)+\"_nn\"+str(nn_nodes) +\"_target\"+str(target_recall)\n",
        "\n",
        "\n",
        "callback_log = tensorboard_log+'running/'\n",
        "# Checkpoint callback to save the model periodically\n",
        "checkpoint_callback = CheckpointCallback(save_freq=10000, save_path=callback_log, name_prefix=tb_log_name)\n",
        "\n",
        "\n",
        "\n",
        "# patience is set to patience steps\n",
        "patience = 10*n_steps*n_envs #as a general early stopping rule, allow for 10 rollouts w/o improvement more than 1%\n",
        "\n",
        "early_stopping_callback = EarlyStoppingCallback(patience=patience, min_delta=0.001, verbose=1)\n",
        "\n",
        "\n",
        "\n",
        "# Combine the callbacks\n",
        "callbacks = [checkpoint_callback, early_stopping_callback]\n",
        "\n",
        "model = PPO(\n",
        "    policy = 'MlpPolicy',\n",
        "    env = vec_env_train,\n",
        "    n_steps = n_steps,\n",
        "    batch_size = batch_size,\n",
        "    n_epochs = n_epochs,\n",
        "    gamma = gamma,\n",
        "    gae_lambda = gae_lambda,\n",
        "    ent_coef = ent_coef,\n",
        "    clip_range = clip_range,\n",
        "    verbose=0,\n",
        "    learning_rate = learning_rate,\n",
        "    policy_kwargs=policy_kwargs,\n",
        "    seed=0,\n",
        "    tensorboard_log= tensorboard_log)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.learn(total_timesteps=total_timesteps, tb_log_name=tb_log_name, callback=callbacks)\n",
        "\n",
        "model.save(tensorboard_log+'model_'+tb_log_name)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPUQjmYvKUeN"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir \"$tensorboard_log\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knQiPHlAKUeP"
      },
      "source": [
        "## TESTING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNRNVPMRKUeQ"
      },
      "source": [
        "### Load Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Wr4ctQKKUeQ"
      },
      "outputs": [],
      "source": [
        "TRAINING = False\n",
        "\n",
        "\n",
        "model_load_dir = tensorboard_log + 'model_'+tb_log_name\n",
        "\n",
        "\n",
        "model = PPO.load(model_load_dir, env=vec_env_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEpPCVykKUeR"
      },
      "source": [
        "### all targets & datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y75xOyusKUeR"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "dataset_names = [\"CLEF2017\", \"CLEF2018\", \"CLEF2019\"]\n",
        "\n",
        "qrels_dic = {\n",
        "    \"CLEF2017\" : \"data/qrels/CLEF2017_qrels.txt\",\n",
        "    \"CLEF2018\" : \"data/qrels/CLEF2018_qrels.txt\",\n",
        "    \"CLEF2019\" : \"data/qrels/CLEF2019_qrels.txt\",\n",
        "}\n",
        "rankings_dic = {\n",
        "    \"CLEF2017\" : \"data/rankings/clef2017_ranking.txt\",\n",
        "    \"CLEF2018\" : \"data/rankings/clef2018_ranking.txt\",\n",
        "    \"CLEF2019\" : \"data/rankings/clef2019_ranking.txt\",\n",
        "}\n",
        "\n",
        "\n",
        "target_recalls = [1.0, 0.9, 0.8, 0.7]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ek-Byzl6KUeR"
      },
      "source": [
        "### results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w56U3Ey1KUeR"
      },
      "outputs": [],
      "source": [
        "TRAINING = False\n",
        "\n",
        "total_runs = 1\n",
        "topic_set = 'test'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### all targets & datasets\n",
        "for dataset_name in dataset_names:\n",
        "\n",
        "  # file name\n",
        "  ALL_VECTORS_PREDICTIONS_DIC_file_name = dataset_name +'_'+ topic_set +'_'+ 'ALL_VECTORS_PREDICTIONS_DIC.pkl'\n",
        "  ALL_VECTORS_PREDICTIONS_DIC_file_name = DRL_DIR+'data/'+ALL_VECTORS_PREDICTIONS_DIC_file_name\n",
        "\n",
        "  # check if the file exists\n",
        "  if not os.path.exists(ALL_VECTORS_PREDICTIONS_DIC_file_name):\n",
        "    # if doesn't exist, create an empty dictionary\n",
        "    ALL_VECTORS_PREDICTIONS_DIC = {}\n",
        "    SELECTED_TOPICS_WITHOUT_TARGET = []\n",
        "    ALL_VECTORS_PREDICTIONS_DIC_EXIST = False\n",
        "  else:\n",
        "    # if exists, load the dictionary from the file\n",
        "    with open(ALL_VECTORS_PREDICTIONS_DIC_file_name, \"rb\") as f:\n",
        "      ALL_VECTORS_PREDICTIONS_DIC = pickle.load(f)\n",
        "      SELECTED_TOPICS_WITHOUT_TARGET = list(ALL_VECTORS_PREDICTIONS_DIC.keys())\n",
        "      ALL_VECTORS_PREDICTIONS_DIC_EXIST = True\n",
        "\n",
        "  qrels = qrels_dic[dataset_name]\n",
        "\n",
        "  qrel_fname, query_rel_dic = load_rel_data(qrels)\n",
        "\n",
        "  run = rankings_dic[dataset_name]\n",
        "  #doc_rank_dic, rank_rel_dic = load_run_data(run)\n",
        "  doc_rank_dic, rank_rel_dic, rank_text_dic, rank_tfidf_dic = load_run_data_with_text_tfidf(run, dataset_name, topic_set)\n",
        "\n",
        "  topics_list = make_topics_list(doc_rank_dic,1)  # sort topics by no docs\n",
        "\n",
        "  if dataset_name == 'CLEF2019':\n",
        "      #remove topic CD012164 last element, contains 61 items only, < 100 vector size\n",
        "      topics_list= topics_list[:-1]\n",
        "\n",
        "  for target_recall in target_recalls:\n",
        "\n",
        "    # Instantiate the vec env\n",
        "\n",
        "    #random topic selection for each env instance\n",
        "    SELECTED_TOPICS = [] # reset before/after each call, keep track of all randomly selected topics\n",
        "\n",
        "    vec_env = make_vec_env(TAREnv, n_envs=len(topics_list), env_kwargs=dict(target_recall=target_recall, topics_list = topics_list, topic_id=None, size=100, render_mode='human'))\n",
        "\n",
        "    SELECTED_TOPICS = [] # reset before/after each call, keep track of all randomly selected topics\n",
        "\n",
        "    test_size = len(topics_list)\n",
        "    vec_env_test = vec_env\n",
        "\n",
        "    df = pd.DataFrame()\n",
        "    df_all_runs = pd.DataFrame()\n",
        "\n",
        "    for run in range(total_runs):\n",
        "\n",
        "      # Test the trained agent\n",
        "      # using the vecenv\n",
        "      vec_env_test = vec_env\n",
        "      obs = vec_env_test.reset()\n",
        "      test_steps = 100\n",
        "      vector_size = 100\n",
        "\n",
        "\n",
        "      n_env = test_size\n",
        "      agent=0\n",
        "      target=0\n",
        "      agent_vector=[]\n",
        "      terminal_observation=[]\n",
        "\n",
        "      topics = []\n",
        "      recalls = []\n",
        "      costs=[]\n",
        "      e_costs = []\n",
        "      reliabilities = []\n",
        "      rewards = []\n",
        "      distances = []\n",
        "      differences = []\n",
        "      targets = []\n",
        "      run_cnts = []\n",
        "\n",
        "      for eID in range(test_size):\n",
        "        print(f\"=================== env {eID}\")\n",
        "        env = vec_env_test.envs[eID]\n",
        "        obs, info = env.reset()\n",
        "\n",
        "        for step in range(test_steps):\n",
        "\n",
        "          action, _ = model.predict(obs, deterministic=True) # predict all next steps\n",
        "\n",
        "          obs, reward, done, trun,info = env.step(action)\n",
        "\n",
        "          if done or trun:\n",
        "                      topic_id = info['topic_id']\n",
        "                      recall = info['recall']\n",
        "                      cost = info['cost']\n",
        "                      e_cost =  info['e_cost']\n",
        "\n",
        "                      distance = info['distance']\n",
        "\n",
        "                      agent = info['agent']\n",
        "                      target = info['target']\n",
        "                      agent_vector = info['agent_vector']\n",
        "                      terminal_observation = info['terminal_observation']\n",
        "\n",
        "                      difference = target_recall - recall\n",
        "\n",
        "\n",
        "\n",
        "                      reliability = 1 if recall >= target_recall else 0\n",
        "                      topics.append(topic_id)\n",
        "                      recalls.append(recall)\n",
        "                      costs.append(cost)\n",
        "                      e_costs.append(e_cost)\n",
        "                      reliabilities.append(reliability)\n",
        "                      rewards.append(reward)\n",
        "                      distances.append(distance)\n",
        "                      targets.append(target)\n",
        "                      run_cnts.append(run)\n",
        "                      differences.append(difference)\n",
        "\n",
        "                      df_tmp = pd.DataFrame( list(zip([dataset_name]*len(topics_list), topics, run_cnts, recalls, reliabilities, costs, e_costs, rewards, differences, distances, targets)),\n",
        "                      columns =['Dataset', 'Topic', 'Run', 'Recall', 'Reliability', 'Cost', 'e-Cost', 'Reward', 'Difference', 'Distance', 'Target'])\n",
        "\n",
        "\n",
        "                      df = pd.concat([df_tmp])\n",
        "\n",
        "\n",
        "                      df.groupby('Topic').mean(numeric_only=True)\n",
        "\n",
        "                      break\n",
        "\n",
        "\n",
        "\n",
        "      df_all_runs = pd.concat([df_all_runs, df])\n",
        "\n",
        "\n",
        "\n",
        "    df_all_runs['Model'] = model_name\n",
        "    df_all_runs['Model_settings'] = tb_log_name\n",
        "    df_all_runs['Target_Recall'] = target_recall\n",
        "\n",
        "\n",
        "\n",
        "    df_all_targets = pd.concat([df_all_targets, df_all_runs], ignore_index = True)\n",
        "\n",
        "    #save dic for first time\n",
        "    if not ALL_VECTORS_PREDICTIONS_DIC_EXIST:\n",
        "        # Save the dictionary to a file\n",
        "        with open(ALL_VECTORS_PREDICTIONS_DIC_file_name, 'wb') as f:\n",
        "            pickle.dump(ALL_VECTORS_PREDICTIONS_DIC, f)\n",
        "\n",
        "\n",
        "display(df_all_targets)\n",
        "\n",
        "display(df_all_targets.describe())\n",
        "\n",
        "display(df_all_targets.groupby(['Target_Recall','Dataset']).mean(numeric_only=True).round(3))\n",
        "display(df_all_targets.groupby(['Target_Recall','Dataset']).std(numeric_only=True).round(3))\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "6OfYu6PpKUeT",
        "h3kTyNxhKUer",
        "XucMp1jrKUer",
        "L_m3PgsAKUet",
        "-vYKTE9JKUet",
        "zJ9MctX2Id3t",
        "9dFJ5oSOPBw6",
        "o5r9nM3LId3v",
        "UO_h3GI2Iwbu",
        "BibKjQzxIwbw",
        "jjqCriWRIwbx",
        "CBZDmJKnIwbx",
        "1-rMZja54cf8",
        "gzUHZper4cf-",
        "9zGX1wEh4cgA",
        "WZHUvlLw4cgB",
        "iaeqAfb1Eks6",
        "k9k5FPM74cgC",
        "pgAe_YCx4cgD",
        "c2qi2ykqoLNR",
        "LfBciPy_oLNR",
        "7jUmSq_qoLNZ"
      ],
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}